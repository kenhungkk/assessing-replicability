% For all the additional stuff that should not be overwritten everytime papers.bib gets regenerated from my citation manager.

@misc{Srivastava:2016,
author = {Srivastava, Sanjay},
title = {Evaluating a new critique of the Reproducibility Project},
journal = {The Hardest Science},
type = {Blog},
year = {2016},
month = mar,
url = {https://thehardestscience.com/2016/03/03/evaluating-a-new-critique-of-the-reproducibility-project/}
}

@misc{Srivastava:2015,
author = {Srivastava, Sanjay},
title = {Moderator interpretations of the Reproducibility Project},
journal = {The Hardest Science},
type = {Blog},
year = {2015},
month = sep,
url = {https://thehardestscience.com/2015/09/02/moderator-interpretations-of-the-reproducibility-project/}
}

@misc{Nosek:2016,
author = {Nosek, Brian A and Gilbert, Elizabeth},
title = {Let’s not mischaracterize replication studies: authors},
journal = {Retraction Watch},
type = {Blog},
year = {2016},
month = mar,
url = {https://retractionwatch.com/2016/03/07/lets-not-mischaracterize-replication-studies-authors/}
}

@misc{Hung:2018,
author = {Hung, Kenneth and Fithian, William},
title = {Supplement to ``{S}tatistical Methods for Replicability Assessment''},
type = {Supplement},
year = {2018},
month = nov
}

@article{Heller:2007,
title = {Conjunction group analysis: an alternative to mixed/random effect analysis},
author = {Heller, Ruth and Golland, Yulia and Malach, Rafael and Benjamini, Yoav},
journal = {Neuroimage},
volume = {37},
number = {4},
pages = {1178--1185},
year = {2007},
publisher = {Elsevier}
}

@article{Zollner:2007,
title = {Overcoming the winner’s curse: estimating penetrance parameters from case-control data},
author = {Z{\"o}llner, Sebastian and Pritchard, Jonathan K},
journal = {The American Journal of Human Genetics},
volume = {80},
number = {4},
pages = {605--615},
year = {2007},
publisher = {Elsevier}
}

@article{Sampson:2005,
title = {Drop-the-Losers Design: Normal Case},
author = {Sampson, Allan R and Sill, Michael W},
journal = {Biometrical Journal},
volume = {47},
number = {3},
pages = {257--268},
year = {2005},
publisher = {Wiley Online Library}
}

@article{Weinstein:2013,
author = {Weinstein, Asaf and Fithian, William and Benjamini, Yoav},
journal = {Journal of the American Statistical Association},
number = {501},
pages = {165--176},
publisher = {Taylor \& Francis Group},
title = {Selection adjusted confidence intervals with more power to determine the sign},
volume = {108},
year = {2013}
}

@article{Yekutieli:2012,
title = {Adjusted Bayesian inference for selected parameters},
author = {Yekutieli, Daniel},
journal = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
volume = {74},
number = {3},
pages = {515--541},
year = {2012},
publisher = {Wiley Online Library}
}

@unpublished{Klein:2018,
author = {Klein, Richard A and Vianello, Michelangelo and Hasselman, Fred and Adams, Byron G and Adams, Reginald B and Alper, Sinan and Aveyard, Mark and Axt, Jordan R and Bahn{\'{i}}k, {\v{S}}t{\v{e}}p{\'{a}}n and Batra, Rishtee and Berkics, Mih{\'{a}}ly and Bernstein, Michael J and Berry, Daniel and Bialobrzeska, Olga and Binan, Evans and Bocian, Konrad and Brandt, Mark J and Busching, Robert and R{\'{e}}dei, Anna Cabak and Cai, Huajian and Cambier, Fanny and Cantarero, Katarzyna and Carmichael, Cheryl L and Ceric, Francisco and Cicero, David C and Chandler, Jesse and Chatard, Armand and Chen, Eva E and Chang, Jen-Ho and Cheong, Winnee and Coen, Sharon and Coleman, Jennifer A and Collisson, Brian and Conway, Morgan A and Corker, Katherine S and Curran, Paul G and Cushman, Fiery and Dagona, Zubairu K and Dalgar, Ilker and {Dalla Rosa}, Anna and David, William E and de Brujin, Maaike and {De Schutter}, Leander and Devos, Thierry and Doğulu, Canay and Dozo, Nerisa and Dukes, Kristin Nicole and Dunham, Yarrow and Durrheim, Kevin and Ebersole, Charles R and Edlund, John E and English, Alexander Scott and Eller, Anja and Finck, Carolyn and Frankowska, Natalia and Freyre, Miguel-{\'{A}}ngel and Friedman, Mike and Galliani, Elisa Maria and Gandi, Joshua C and Ghoshal, Tanuka and Giessner, Steffen R and Gill, Tripat and Gnambs, Timo and G{\'{o}}mez, {\'{A}}ngel and Gonz{\'{a}}lez, Roberto and Graham, Jesse and Grahe, Jon E and Grahek, Ivan and Green, Eva G T and Hai, Kakul and Haigh, Matthew and Haines, Elizabeth L and Hall, Michael P and Heffernan, Marie E and Hicks, Joshua A and Houdek, Petr and Huntsinger, Jeffrey R and Huynh, Ho Phi and IJzerman, Hans and Inbar, Yoel and Innes-Ker, {\AA}se H and Jim{\'{e}}nez-Leal, William and John, Melissa-Sue and Joy-Gaba, Jennifer A and Kende, Anna and Kamiloğlu, Roza G and Kappes, Heather Barry and Karabati, Serdar and Karick, Haruna and Keller, Victor N and Kervyn, Nicolas and Kne{\v{z}}evi{\'{c}}, Goran and Kovacs, Carrie and Krueger, Lacy E and Kurapov, German and Kurtz, Jamie and Lakens, Dani{\"{e}}l and Lazarevi{\'{c}}, Ljiljana B and Levitan, Carmel A and {Neil A Lewis}, Jr and Lins, Samuel and Lipsey, Nikolette P and Losee, Joy and Maassen, Esther and Maitner, Angela T and Malingumu, Winfrida and Mallett, Robyn K and Marotta, Saita A and Međedovi{\'{c}}, Janko and {Mena Pacheco}, Fernando and Milfont, Taciano L and Morris, Wendy L and Murphy, Sean and Myachykov, Andriy and Neave, Nick and Neijenhuijs, Koen and Nelson, Anthony J and Neto, F{\'{e}}lix and Nichols, Austin Lee and Ocampo, Aaron and ODonnell, Susan L and Ong, Elsie and Osowiecka, Malgorzata and Orosz, G{\'{a}}bor and Packard, Grant and P{\'{e}}rez-S{\'{a}}nchez, Rolando and Petrovi{\'{c}}, Boban and Pilati, Ronaldo and Pinter, Brad and Podesta, Lysandra and Pogge, Gabrielle and Pollmann, Monique M H and Rutchick, Abraham M and Saeri, Alexander and Saavedra, Patricio and Salomon, Erika and Schmidt, Kathleen and Sch{\"{o}}nbrodt, Felix D and Sekerdej, Maciej B and Sirlop{\'{u}}, David and Skorinko, Jeannie L M and Smith, Michael A and Smith-Castro, Vanessa and Smolders, Karin and Sobkow, Agata and Sowden, Walter and Srivastava, Manini and Sundfelt, Oskar K and Spachtholz, Philipp and Steiner, Troy G and Stouten, Jeroen and Street, Chris N H and Szeto, Stephanie and Szumowska, Ewa and Tang, Andrew and Tanzer, Norbert and Tear, Morgan and Thomae, Manuela and Traczyk, Jakub and Torres, David and Theriault, Jordan and Tybur, Joshua M and Ujhelyi, Adrienn and van Aert, Robbie C M and van Assen, Marcel A L M and van Lange, Paul A M and van der Hulst, Marije and {van 't Veer}, Anna Elisabeth and {V{\'{a}}squez Echeverr{\'{i}}a}, Alejandro and Vaughn, Leigh Ann and V{\'{a}}squez, Alexandra and Vega, Luis Diego and Verniers, Catherine and Verschoor, Mark and Voermans, Ingrid and Vranka, Marek A and de Vries, Marieke and Welch, Cheryl and Wichman, Aaron and Williams, Lisa A and Wood, Michael and Woodzicka, Julie A and Wronska, Marta K and Young, Liane and Zelenski, John M and Zeng, Zhijia and Nosek, Brian A},
booktitle = {PsyArXiv},
file = {:Users/Kenneth/Documents/Papers/Klein et al/2018/Klein et al. - 2018 - PsyArXiv.pdf:pdf},
keywords = {Cognitive psychology,Culture,Individual differences,Meta-analysis,Replication,Sampling effects,Situational effects,Social psychology},
month = {oct},
pages = {1--100},
title = {{Many Labs 2: Investigating Variation in Replicability Across Sample and Setting}},
url = {https://psyarxiv.com/9654g/},
year = {2018}
}

@article{vanAert:2017,
abstract = {The vast majority of published results in the literature is statistically significant, which raises concerns about their reliability. The Reproducibility Project Psychology (RPP) and Experimental Economics Replication Project (EE-RP) both replicated a large number of published studies in psychology and economics. The original study and replication were statistically significant in 36.1{\%} in RPP and 68.8{\%} in EE-RP suggesting many null effects among the replicated studies. However, evidence in favor of the null hypothesis cannot be examined with null hypothesis significance testing. We developed a Bayesian meta-analysis method called snapshot hybrid that is easy to use and understand and quantifies the amount of evidence in favor of a zero, small, medium and large effect. The method computes posterior model probabilities for a zero, small, medium, and large effect and adjusts for publication bias by taking into account that the original study is statistically significant. We first analytically approximate the methods performance, and demonstrate the necessity to control for the original study's significance to enable the accumulation of evidence for a true zero effect. Then we applied the method to the data of RPP and EE-RP, showing that the underlying effect sizes of the included studies in EE-RP are generally larger than in RPP, but that the sample sizes of especially the included studies in RPP are often too small to draw definite conclusions about the true effect size. We also illustrate how snapshot hybrid can be used to determine the required sample size of the replication akin to power analysis in null hypothesis significance testing and present an easy to use web application (https://rvanaert.shinyapps.io/snapshot/) and R code for applying the method.},
author = {van Aert, Robbie C M and van Assen, Marcel A L M},
doi = {10.1371/journal.pone.0175302},
file = {:Users/Kenneth/Documents/Papers/PLoS ONE/van Aert, van Assen - 2017 - PLoS ONE.pdf:pdf},
isbn = {1111111111},
issn = {1932-6203},
journal = {PLoS ONE},
keywords = {Effect size,Statistics},
number = {4},
pages = {e0175302--23},
title = {{Bayesian evaluation of effect size after replicating an original study}},
url = {http://dx.plos.org/10.1371/journal.pone.0175302},
volume = {12},
year = {2017}
}

@article{vanAert:2018,
abstract = {The unrealistically high rate of positive results within psychology has increased the attention to replication research. However, researchers who conduct a replication and want to statistically combine the results of their replication with a statistically significant original study encounter problems when using traditional meta-analysis techniques. The original study's effect size is most probably overestimated because it is statistically significant, and this bias is not taken into consideration in traditional meta-analysis. We have developed a hybrid method that does take the statistical significance of an original study into account and enables (a) accurate effect size estimation, (b) estimation of a confidence interval, and (c) testing of the null hypothesis of no effect. We analytically approximate the performance of the hybrid method and describe its statistical properties. By applying the hybrid method to data from the Reproducibility Project: Psychology (Open Science Collaboration, 2015), we demonstrate that the conclusions based on the hybrid method are often in line with those of the replica-tion, suggesting that many published psychological studies have smaller effect sizes than those reported in the original study, and that some effects may even be absent. We offer hands-on guidelines for how to statistically combine an original study and replication, and have developed a Web-based application (https://rvanaert.shinyapps.io/hybrid) for applying the hybrid method.},
author = {van Aert, Robbie C M and van Assen, Marcel A L M},
doi = {10.3758/s13428-017-0967-6},
file = {:Users/Kenneth/Documents/Papers/Behavior Research Methods/van Aert, van Assen - 2018 - Behavior Research Methods.pdf:pdf},
isbn = {1342801709676},
issn = {15543528},
journal = {Behavior Research Methods},
keywords = {Meta-analysis,Replication,Reproducibility,p-Uniform},
number = {4},
pages = {1515--1539},
pmid = {3295148},
publisher = {Behavior Research Methods},
title = {{Examining reproducibility in psychology: A hybrid method for combining a statistically significant original study and a replication}},
volume = {50},
year = {2018}
}

@unpublished{Morey:2017,
abstract = {Millions of people worldwide are exposed to arsenic-contaminated drinking water. Arsenic field test kits may offer a cost-effective approach for measuring these exposures in the field, although the accuracy of some kits used in the past has been poor. In this study, arsenic concentrations were measured in 136 water sources in western Nevada using two relatively new arsenic test kits and compared to laboratory measurements using atomic fluorescence spectroscopy (AFS). Spearman's rank correlation coefficients comparing the Quick Arsenic and Hach EZ kits to laboratory measurements were 0.96 (p {\textless} 0.001) and 0.95 (p {\textless} 0.001), respectively. When analyzed in seven exposure categories (09, 1019, 2049, 5099, 100199, 200499, and 500 mug/L), test kit and AFS measurements were in the same category in 71{\%} (Quick Arsenic) and 62{\%} (Hach EZ) of samples, and within one category of each other in 99{\%} (Quick Arsenic) and 97{\%} (Hach EZ) of samples. Both kits identified all water samples with high arsenic concentrations ({\textgreater} 15 mug/L) as being above the United States Environmental Protection Agency's drinking water standard and the World Health Organization's guideline value for arsenic of 10 mug/L. These results suggest that these easily portable kits can be used to identify water sources with high arsenic concentrations and may provide an important tool for arsenic surveillance and remediation programs.},
author = {Morey, Richard D and Lakens, Dani{\"{e}}l},
booktitle = {GitHub},
doi = {doi:10.1021/es060015i},
file = {:Users/Kenneth/Documents/Papers/GitHub/Morey, Lakens - 2017 - GitHub.pdf:pdf},
issn = {1756-3305},
number = {1977},
pages = {1--32},
title = {{Why most of psychology is statistically unfalsifiable}},
url = {https://github.com/richarddmorey/psychology\_resolution},
year = {2017}
}
